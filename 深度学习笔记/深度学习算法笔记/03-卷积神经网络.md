# 卷积神经网络

## 什么是卷积神经网络

卷积神经网络`(Convolutional Neural Network，CNN or ConvNet)`是一种具有局部连接、权值共享等特点的深层前馈神经网络，目前在图像和视频分析领域取得了显著的成功，是目前应用最为广泛的模型之一。

## 卷积与池化

卷积与池化是卷积神经网络中的两个核心操作，大多数的神经网络结构都是将它们组合而得到的。

### 信号处理中的卷积

**来源**：卷积一词是来自于信号处理领域，是一项广泛应用于信号处理，图像处理以及其他工程科学领域的技术。

**典型应用**：针对某个线性时不变的系统，给定输入信号$f(\tau)$和系统响应$g(\tau)$，求系统的输出。

**数学定义**：
$$
(f*g)(t) = \int_{-\infty}^{\infty}f(\xi)g(t-\tau)d\tau
$$
**含义**：函数$g(\tau)$经过翻转和平移$t$后，得到$g(t-\tau)$，再求与函数$f(\tau)$乘积的积分。

![image-20210228153530879](assets/03-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20210228153530879.png)

### 图像中的卷积

接下来以图像为例来直观地理解卷积，计算机中的图像通常都是按照像素点以离散的形式存储的，可以用一个二维或者三维的矩阵来表示。

假设对于一个二维的图像$X \in R^{H\times W}$，卷积核为$G\in R^{k\times k}$，通常$k$为奇数，二维离散卷积的计算方式如下：
$$
Y_{m,n} = \sum\limits_{i=-|\frac{k}{2}|}^{\frac{2}{k}} \sum\limits_{j=-|\frac{k}{2}|}^{\frac{k}{2}} X_{m-i,n-j} G_{i,j}
$$
![img](assets/03-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/5.1_correlation.svg)

* pytorch

```
import torch

def corr2d(X,K):
    h,w = K.shape
    m,n = X.shape
    
    Y = torch.zeros((m-h+1,n-w+1))
    for i in range(Y.shape[0]):
        for j in range(Y.shape[1]):
            Y[i,j] = (X[i:i+h,j:j+w]*K).sum()
    return Y


X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])
K = torch.tensor([[0, 1], [2, 3]])
corr2d(X,K)
```

* tensorflow

直观理解上述卷积过程：先将卷积核选择$180^。$，然后在输入中的对应位置去除一个大小为$k \times k $的区域，得到对应位置的输出。

在传统的图像处理中，卷积核通常是人为设定的，不同的卷积核可以提取输入中的某种特征，得到不同的输出。如下展示了两种不同的卷积核`Sobel`和`Laplacian`，它们都可以用于提取图像的边缘，但`Laplacian`是一个二阶的算子，而`Sobel`是一个一阶的算子，因此应用它们得到的边缘检测效果有明显的差异。也就是说，不同的卷积核可以提取到不一样的特征。

![image-20210228154726025](assets/03-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20210228154726025.png)

### 二维卷积层

二维卷积层将输入和卷积核做互相关运算，并加上一个标量偏差来得到输出。卷积层的模型参数包括了卷积核和标量偏差。在训练模型的时候，通常我们先对卷积核随机初始化，然后不断迭代卷积核和偏差。

* pytorch

```
class Conv2D(torch.nn.Module):
    
    def __init__(self,kernel_size):
        super(Conv2D,self).__init__()
        self.weight = torch.nn.Parameter(torch.randn(kernel_size))
        self.bias = torch.nn.Parameter(torch.randn(1))
        
    def forward(self,x):
        return corr2d(x,self.weight) + self.bias
```

**一个卷积层的简单应用（1）**：检测图像中物体的边缘，即找到像素变化的位置。首先我们构造一张6×8的图像（即高和宽分别为6像素和8像素的图像）。它中间4列为黑（0），其余为白（1）。

* pytorch

```
X = torch.ones(6, 8)
X[:, 2:6] = 0
X
```

![image-20210228162711113](assets/03-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20210228162711113.png)

然后构造一个卷积核，进行计算，可以看出，我们将从白到黑的边缘和从黑到白的边缘分别检测成了1和-1。其余部分的输出全是0。：

```
K = torch.tensor([
    [1,-1]
])
Y = corr2d(X,K)
Y
```

![image-20210228162837600](assets/03-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20210228162837600.png)

由此，可以看出，卷积层可通过重复使用卷积核有效地表征局部空间。

**一个卷积层的简单应用（2）**：使用物体边缘检测中的输入数据`X`和输出数据`Y`来学习构造的核数组`K`。首先构造一个卷积层，其卷积核将被初始化成随机数组。接下来在每一次迭代中，使用平方误差来比较`Y`和卷积层的输出，然后计算梯度来更新权重。

```
conv2d = Conv2D(kernel_size=(1,2))

step = 20
lr = 0.01
for i in range(step):
    Y_hat = conv2d(X)
    l = ((Y_hat - Y)**2).sum()
    l.backward()
    
    # 梯度下降
    conv2d.weight.data -= lr*conv2d.weight.grad
    conv2d.bias.data -= lr*conv2d.bias.grad
    
    # 梯度清零
    conv2d.weight.grad.zero_()
    conv2d.bias.grad.zero_()
    
    if (i + 1) % 5 == 0:
        print('Step %d, loss %.3f' % (i + 1, l.item()))
```

![image-20210228163829256](assets/03-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20210228163829256.png)

### 卷积的意义

**意义**：在于可以将时域中复杂的卷积运算转换为频域中简单的相乘运算。
$$
(f*g)(t) \Leftrightarrow F(w)G(w)
$$
要理解卷积定理，还需要知道傅里叶变换。**傅里叶变换**是将时域中的数据转换到频域中的一种方法，它将函数分解为一系列不同频率的三角函数的叠加，可以将它理解为从另一个维度去观察数据。

### 深度学习中的卷积操作

#### 单通道卷积

* 定义

$$
H_{m,n} = \sum\limits_{i=-|\frac{k}{2}|}^{\frac{2}{k}} \sum\limits_{j=-|\frac{k}{2}|}^{\frac{k}{2}} X_{m+i,n+j} G_{i,j}
$$

![image-20210228155907399](assets/03-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20210228155907399.png)

#### 多通道卷积

设输入$X∈R^{H×W×C}$，C表示通道（channels）数，卷积核的长宽都为$k$。由于输入有多个通道，因此我们赋予每个通道一个$k×k$的卷积核，这些卷积核构成$G^{c'}∈R^{k×k×C}$，这样多通道卷积可以定义为：
$$
H_{m,n,c^{'}} = \sum\limits_{i=-|\frac{k}{2}|}^{\frac{2}{k}} \sum\limits_{j=-|\frac{k}{2}|}^{\frac{k}{2}} X_{m+i,n+j}\cdot G^{c^{'}}_{i,j}
$$
![img](assets/03-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/5.3_conv_multi_in.svg)



### 池化

目的：**为了缓解卷积层对位置的过度敏感性**。

同卷积层一样，池化层每次对输入数据的一个固定形状窗口（又称池化窗口）中的元素计算输出。不同于卷积层里计算输入和核的互相关性，池化层直接计算池化窗口内元素的最大值或者平均值。该运算也分别叫做最大池化或平均池化。在二维最大池化中，池化窗口从输入数组的最左上方开始，按从左往右、从上往下的顺序，依次在输入数组上滑动。当池化窗口滑动到某一位置时，窗口中的输入子数组的最大值即输出数组中相应位置的元素。

![img](assets/03-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/5.4_pooling.svg)

池化窗口形状为2×22\times 22×2的最大池化，阴影部分为第一个输出元素及其计算所使用的输入元素。输出数组的高和宽分别为2，其中的4个元素由取最大值运算$\text{max}$得出：
$$
max(0,1,3,4)=4,\\
max(1,2,4,5)=5,\\
max(3,4,6,7)=7,\\
max(4,5,7,8)=8.\\
$$
二维平均池化的工作原理与二维最大池化类似，但将最大运算符替换成平均运算符。池化窗口形状为$p×q$的池化层称为$p×q$池化层，其中的池化运算叫作$p×q$池化。

* pytorch

```
def pool2d(X,pool_size,mode="max"):
    X = X.float()
    p_h,p_w = pool_size
    Y = torch.zeros(X.shape[0]-p_h+1,X.shape[1]-p_w+1)
    for i in range(Y.shape[0]):
        for j in range(Y.shape[1]):
            if mode == "max":
                Y[i,j] = X[i:i+p_h,j:j+p_w].max()
            elif mode == "avg":
                Y[i,j] = X[i:i+p_h,j:j+p_w].mean()
    return Y

X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])
pool2d(X, (2, 2))
```

![image-20210228165654724](assets/03-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20210228165654724.png)

或者

```
X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])
X = X.view((1, 1, X.shape[0], -1)).float()
# padding，stride并分别指定高和宽上的填充和步幅
pool2d = torch.nn.MaxPool2d(2, padding=0, stride=1)
pool2d(X)
```

