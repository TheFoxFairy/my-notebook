# 图神经网络在虚拟网络嵌入的应用

## 介绍

随着最近第五代移动网络$(5G)$的出现和需要支持的服务多样化，基础设施提供商$(InPs)$被迫适应这些新的变化，特别是要求部署受限制的服务几乎是即时的。

由于**硬件解决方案过于僵化，不适合实时部署**，$InPs$正在转向新的可伸缩软件解决方案，随着网络功能虚拟化$(NFV)$范式的出现。$NFV$允许多个虚拟网络请求$(VNRs)$共存于同一基板网络$(SN)$之上。虚拟网络嵌入$(Virtual\  Network\ embedding, VNE)$问题被认为是网络虚拟化中主要的**资源分配**问题。事实上，它已经被定义为一个非常高计算复杂度的问题。

$VNE$最重要的挑战之一是**有效和自动地部署网络服务**，这将使它有可能收敛到一个完全自动化的网络，也称为零接触网络`(zero-touch network)​`。

本论文提出了一个基于$DRL$和图卷积神经网络的**端到端**解决方案来训练一个$agent$来解决$VNE$问题。

该论文的贡献可以总结如下:

* **将$VNE$问题形式化为$MDP(马尔科夫决策过程)$**
* **基于$gcn$的神经结构的特征自动提取**
* **提出一个更有效的安置策略**

## 问题定义

### 前提

设$\mathcal{G} = (V,  E)$是一个图，其中$V$是图的结点集，$E$是图的边集。我们假设每个结点$n\in V$都有一个输入特征向量$in_n$。图卷积运算将特征向量$in_n$作为输入，输出一个新的向量$out_n$，如下式所示:
$$
out_n = f(\sum_{m \in \mathcal{N}(n)} \frac{1}{\sqrt{d_md_n}}in_mW^{l}]) \tag{1}
$$
其中$\mathcal N(n)$为结点$n$及其邻域组成的集合，$d_m$为结点$m + $1的度数，$W^{l}$为$l^{th}\ GCN$层的权矩阵，$f$为激活函数。

### 术语

| notation                                                     | description                                                  |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| $\mathcal G^s=(\mathbb N^s,\mathbb L^s),\mathcal G^v=(\mathbb N^v,\mathbb L^v)$ | 底层网络图和虚拟网络请求$(VNR)$图                            |
| $\mathbb L^s,\mathbb L^v$                                    | 底层链路和虚拟链路                                           |
| $\mathbb P^s$                                                | 底层路径，两个虚拟结点之间的映射的物理结点之间的实际物理路径 |
| $c_{n^s}$                                                    | 底层结点$n^s$所有具有的可用$CPU$，也就是具有的计算能力       |
| $b_{l^s}$                                                    | 底层链路$l^s$所有具有的带宽                                  |
| $c_{n^v}$                                                    | $VNF\ n^v$的$CPU$请求，也就是所需要的计算需求                |
| $b_{l^v}$                                                    | $VL\ l^v$的带宽请求，也就是所需要的带宽需求                  |

### 虚拟网络映射$(VNE)$问题

$VNE$问题可分为两个阶段：

* 虚拟结点映射$VNM$

定义为函数$f_{VNM}： \mathbb N^v\rightarrow \mathbb N^s$，也就是将一个虚拟结点映射到一个底层结点。

在结点映射级别，如果承载虚拟结点的基板结点有足够的$CPU$资源，就成功地部署了虚拟结点，也就是，如果 
$$
c_{n^v} \leq c_{f_{VNM(n^v)}};\forall\ n^v \in \mathbb N^v \tag{2}
$$


> 注意，它必须是单方面映射的，即同一个$VNR(虚拟网络请求)$的两个$VNFs$不能被同一个底层网络托管。

* 虚拟链路映射$VLM$。

$VLM$可以被建模为一个函数$f_{VLM}: \mathbb L^v\rightarrow \mathbb P^s$，它将一个虚拟链路映射到一个物理路径（物理链路）。

在链路映射阶段，如果$VL$的虚拟结点已经部署好，并且映射到物理路径上的每条物理链路都有足够的带宽，则$VL$的部署就成功了，也就是，如果
$$
b_{l^v} \leq \mathop{min}_{l^s \in f_{vlm(l^v)}}b_{f_{VLM(l^v)}};\forall\ l^v \in \mathbb L^v \tag{3}
$$
在这项工作中**，目标是最大限度地接受$VNRs$的数量**。当且仅当它的$VNFs$和$VLs$的放置分别满足约束$(2)$和$(3)$时，一个$VNR$能够被接受。

## 强化学习

基本上所有的强化学习问题，都可以转化为[$MDP$](../../../../..\算法笔记\马尔可夫决策过程.md)问题。

马尔可夫决策过程$(MDP)M=(S,A,P,R,\gamma)$，其中

* $S$：表示状态集合
* $A$：表示一组动作
* $P$：表示在某一状态$S_i$下，采取动作$A_i$，转移到$S_{i+1}$状态的概率，也就是说在确定的状态下采取相应的动作之后不能完全确定下一状态，而是以一定的概率确定下一状态，即$P_{ss'}^a=P(S_{t+1}=s'|S_t=s,A_t=a)$。
* $\gamma$：表示决策过程的一个阻尼系数，用户定义回报在决策过程中随时间打折扣，加快决策过程的收敛，$\gamma \in [0,1]$。
* $R$：表示奖励函数，$R(s)$描述了在状态$s$下**执行某动作**的期望(立即)奖励，$\mathcal R(s,a)=\mathbb E[R_{t+1}|S_t=s,A_t=a]$。

**收获**$G_t$为在一个马尔科夫奖励链上从t时刻开始往后所有的奖励的有衰减的收益总和：
$$
G_t = \mathbb E[\sum\limits_{k=0}^T\gamma^kR_{t+k}],\gamma\in[0,1] \tag{4}
$$
从状态 $s$开始，遵循当前策略时所获得的收获的期望
$$
V^{\pi}(s)=\mathbb{E_{\pi}}[G_t|S_t=s] \tag{5}
$$
通过比较$VNE$与$MDP$的问题，进行实际应用：

**状态表示(State Representation)**：

状态$s$由两个图$(\mathcal G^s,\mathcal G^v)$表示。每个结点$n^s\in \mathbb N^s$有两个特征:

​	$(1)$可用$cpu\ $$c_{n^s}$

​	$(2)$带宽之和定义为属于$n^s$的链路的总可用带宽

另一方面每个$VNF\ n^v\in \mathbb N^v$具有四个特点:

​	$(1)$ $VNF$所需的$cpu$

​	$(2)$ $VNF$所属链路所需的总带宽

​	$(3)$ 一个标志，指示该结点是否是要放置的当前结点

​	$(4)$ 一个标志，指示是否放置了$VNF$

在初始状态$s_0$，第一个$VNF$的当前标志被分配给$1$，其他的被分配给$-1$，所有$VNFs$的放置标志被设置为$-1$。

**行动空间(Action Space)**：在$MDP$的时间步骤$t$，代理必须选择一个底层结点来托管正标记的$VNF(+1)$。注意，同一个$VNR$的$VNFs$不应该放在同一个基板结点上。因此，定义$t$时刻的动作空间为:
$$
A_t = \frac{\mathbb N^s}{\mathbb S_t}\tag{6}
$$
其中，$\mathbb S_t$表示时间步长$t$之前选择的基本结点集。初始化，行动空间$A_0=\mathbb N^s$。

**状态转移动力(State Transition Dynamics)**：在时间步骤$t$, 代理观察状态选择一个动作$A_t= n^s$来放置当前的$VNF\ n^v$，然后$MDP$转换到一个新的状态$ S_{t+1}$，其中两个图的结点特征经历以下更新:

* 如果所选的基本结点有足够的$CPU$资源，那么$VNF\ n^v$将被放置在基本结点$n^s$处。然后，$n^s$的$CPU$将被更新，$c_{n^s}:=c_{n^s}-c_{n^v}$
* 在每次成功放置$VNF$后，将考虑与$VNF$相关的$VLs$以及头部和尾部成功部署$VNFs$。计算头部$VNF$与尾部$VNF$之间的最短路径$l^s\in \mathbb P^s$。如果该$VL$要求的带宽小于该物理路径下所有物理链路提供的带宽，则该物理路径下每条物理链路的可用带宽更新如下:

$$
b_{l^s} = b_{l^s}-b_{l^v},\forall l^s \in \mathbb P^s \tag{7}
$$

* 如果满足上述条件，则将当前结点的放置标志设为$1$，选择另一个未访问的$VNF$作为当前结点。

$VNR$的放置过程最多将结束在$|\mathbb N^v|$步骤。

**奖励设计(Reward design)**：**目标是最大限度地增加接受请求的数量**。为了引导代理人达到这个目标，我们引入了中间和最终奖励。当$VNF$被成功放置时，它会收到一个中间奖励$0$。最终奖励量化代理做出的最终决定的质量。因此，代理在成功放置$VNR$时获得一个单位的奖励。否则，如果$VNR$没有被成功放置，即在过程的某个步骤中存在资源冲突，它将得到$−1$的奖励。

## 基于$gcn$的架构，利用监督学习来解决图相似度计算任务

**使用$GCNs$进行结点级编码**：这一阶段将图的每个结点转换为编码其特征和结构属性的向量。基于$\mathcal G^s$和$\mathcal G^v$两个图中每个结点的原始特征，我们使用$GCNs$对每个结点的邻域信息进行聚合(公式$(1)$)。经过多层$GCNs$，我们得到了两个矩阵$U^s\in \mathbb R^{|N^s|\times D}$和$U^v \in R^{|N^v|\times D}$，分别表示$SN$和$VNR$的结点级编码。每一行$u_n$表示结点$n$的编码，$D$是表示$u_n$维数的超参数。注意，我们使用了两个不同的$GCNs$模块来编码$SN$和$VNR$。

**使用注意层的图形级编码**：在得到结点级编码矩阵$U^s$和$U^v$后，我们可以直接使用它们对图结构进行编码。然而，这在计算上可能是昂贵的。为了克服这个问题，并使图的表示独立于它的大小，我们可以执行结点表示的加权和。获得更高权重的结点的选择取决于我们想放置的当前结点。因此，我们使用注意机制来学习这些权重，而不是考虑固定的权重。对于每个图，我们首先计算一个图上下文$ct$，然后计算图中每个结点的注意力权重。

对于$VNR$，我们定义上下文$ct_v$是当前$VNF$的结点表示，然后是一个非线性变换，$ct_v=  g_v(u_c\times W_c)$，其中$u_c\in \mathbb R^{D}$是当前$VNF$的结点表示，$W_c\in \mathbb R^{D\times D}$是一个可学习的权矩阵，$g_v$是一个激活函数。在此基础上，我们为每一个$VNF\  n^v$计算一个注意权重$a_{n^v}$，即上下文$ct_v$与其编码$u_{n^v}: a_{n^v} = u^T_{n_v}ct_v$之间的内积。最后给出了$VNR$编码的$hv$：
$$
h_v = \sum\limits_{n^v \in \mathbb N^v} a_{n^v}u_{n^v}  \tag{8}
$$
对于$SN$，我们定义其上下文$ct_s$结点编码的简单平均值，然后是一个非线性变换$ct_s= g_s((N^{−1}\sum\limits_{n=1}^{|N^s|}u_n)W_s)$，其中$W_s$是一个可学习的权矩阵，统一了$n^{th}$底层结点的编码。类似地，我们将$SN$的编码定义为基底结点编码的加权和。每个结点的权值等于其编码与上下文的内积，
$$
h_s = \sum\limits_{n^s\in \mathbb N^s}a_{n^s}u_{n^s} \tag{9}
$$
**使用神经张量网络$(NTN)$进行状态级编码**：前面的阶段让代理学习如何对状态的两个图建模。最后一步是学习如何为它们的关系建模。遵循$[17]$，基于$SN$和$VNR$的向量表示，我们使用神经张量网络$(NTN)$来实现：
$$
g(h_s,h_v) = f_3(h_v^TW_3^{[1:K]}h_v+V
\left[\begin{matrix}h_s\\h_v\end{matrix}\right]
+b_3
) \tag{10}
$$
其中$W^{[1:K]}_3$为权量张量，$[]$为级联运算，$V$为权量向量，$b_3$为偏置，$f_3$为激活函数;$K$是超参数。

## 模拟结果

在本节中，我们将介绍仿真设置以及对得到的结果的分析。

$A. $ 模拟设置

为了评估所提议方法的性能，我们考虑以下设置:

* 底层网络是用$Bt\ Europe^1$的网络拓扑结构建模的。包含$24$个节点和$37$条链路。基板节点和链路的容量从区间$[50,100]$均匀抽取。

* 为了生成虚拟请求，我们使用了$ER[18]$模型。在这个模型中，生成的图是由节点的数量$n$和在节点之间创建一条边的概率$p$定义的。例如，当$p = 2 \ln n/n$时，生成的图一般是连通的(更准确地说，当$n \rightarrow \infty时$，这种情况的概率趋于$1$)。$VNRs$请求的资源($CPU$和$BW$)是按照间隔$[1,10]$的均匀分布随机抽取的。该系统以一种偶发的方式运行;在每一集视频中，$VNR$依次到达系统:一旦一个$VNR$被处理，下一个$VNR$就会到达。有$3000$段，每一段有$30$个$VNRs$进入系统。在每一段的结尾，$VNRs$离开系统。我们使用不同的种子执行$5$次运行。
* 对于模型架构，它是用$Python$编写的$Pytorch\ library2$和$DGL\  library3$。神经结构是用以下超参数构建的。我们将`GCN`层数设置为$3$个，并使用$tanh$作为激活函数。对于$NTN$层，我们设$K$为$8$。然后我们使用两个完全连接的层，最后我们有两个头，每一个由一个完全连接的层建模，分别代表政策网络和价值网络。学习速率设置为$10^{−3}$，折现系数$\gamma$设置为$0.99$。为了训练模型，使用了$Adam$优化器$[19]$。

$B.$ 隐藏单元的影响

在代理的神经结构的每一层中使用的隐藏单元的数量既影响得到的解的质量，也影响得到它的计算成本。

![image-20210125183733360](assets/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9C%A8%E8%99%9A%E6%8B%9F%E7%BD%91%E7%BB%9C%E5%B5%8C%E5%85%A5%E7%9A%84%E5%BA%94%E7%94%A8/image-20210125183733360.png)

在本节中，我们将研究隐藏单元的数量对$DRL$代理性能的影响，以便在这两个指标之间找到平衡。我们考虑四个不同的代理:$agent16$、$agent32$、$agent64$和$agent128$，它们在所有隐藏层中分别有$16$、$32$、$64$和$128$个隐藏单元。

![image-20210125183716359](assets/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9C%A8%E8%99%9A%E6%8B%9F%E7%BD%91%E7%BB%9C%E5%B5%8C%E5%85%A5%E7%9A%84%E5%BA%94%E7%94%A8/image-20210125183716359.png)

![image-20210125183805355](assets/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9C%A8%E8%99%9A%E6%8B%9F%E7%BD%91%E7%BB%9C%E5%B5%8C%E5%85%A5%E7%9A%84%E5%BA%94%E7%94%A8/image-20210125183805355.png)

![image-20210125183823495](assets/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9C%A8%E8%99%9A%E6%8B%9F%E7%BD%91%E7%BB%9C%E5%B5%8C%E5%85%A5%E7%9A%84%E5%BA%94%E7%94%A8/image-20210125183823495.png)

图$2$、图$3$和图$4$中显示的结果分别显示了在接受请求数量、部署的$VNFs$数量和部署的$VLs$数量方面的性能。从这些图中我们可以看出，隐藏单位为$64$和$128$的代理比其他代理表现更好，性能更稳定。

![image-20210125183816014](assets/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9C%A8%E8%99%9A%E6%8B%9F%E7%BD%91%E7%BB%9C%E5%B5%8C%E5%85%A5%E7%9A%84%E5%BA%94%E7%94%A8/image-20210125183816014.png)

图$5$显示了每个配置完成一个章节所需的时间。我们拥有的隐藏单位越多，完成这一集的时间就越长。拥有$128$个隐藏单位的特工完成一集所需的时间要比拥有$64$个隐藏单位的特工完成一集所需的时间长，但表现却完全一样。因此，我们使用具有$64$个隐藏单元的代理来比较其与其他解决方案的性能。

$C.$ 性能基准测试

为了对基于$DRL$的解决方案的性能进行基准测试，我们将其与以下方法进行比较：

* **随机代理**：它随机预构造以选择将承载$VNFs$的基板节点。代理根据得到的$VNF$映射，使用最短路径算法寻找$Vls$的链路映射，

* **First Fit**:采用$First-Fit (FF)$算法分配$VNFs$，运行最短路径算法找到每个$VL$的物理路径映射。对于每个$VNF$, $FF$选择第一个具有足够资源的基底节点。

图$6$、图$7$和图$8$分别显示了接受的请求数量以及部署的$VLs$和$VNFs$数量。关于这三个指标，我们的方法优于随机代理和第一拟合程序。与后一种算法不同，我们的方法有效地探索可能的操作，直到找到最优的操作，而$First\  Fit$尝试将$VNFs$放置在第一个有足够资源的基底节点上。因此，它只探索了可能的解决方案的一部分，导致物理链路的剩余带宽的巨大消耗，然后增加了拒绝新到达的请求的可能性。

![image-20210125184131970](assets/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9C%A8%E8%99%9A%E6%8B%9F%E7%BD%91%E7%BB%9C%E5%B5%8C%E5%85%A5%E7%9A%84%E5%BA%94%E7%94%A8/image-20210125184131970.png)

![image-20210125184138203](assets/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9C%A8%E8%99%9A%E6%8B%9F%E7%BD%91%E7%BB%9C%E5%B5%8C%E5%85%A5%E7%9A%84%E5%BA%94%E7%94%A8/image-20210125184138203.png)

## 总结

在本文中，我们提出了一种方法来解决$VNE$问题。该方法基于深度强化学习技术的使用。特别是，我们建议使用$GCNs$，它使我们能够考虑到问题数据的结构，并说明如何使该工具适应考虑到的$VNE$问题。本文还提出了一种新的布局策略，显著提高了这类任务的性能。与现有的传统方法相比，所提出的解决方案已被证明是非常有效的。



